{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "633670e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import zscore\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import nibabel\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "from utils.ridge_tools import cross_val_ridge, corr\n",
    "import time as tm\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "231a0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transpose_zscore(file): \n",
    "    dat = nibabel.load(file).get_data()\n",
    "    dat = dat.T\n",
    "    return zscore(dat,axis = 0)\n",
    "\n",
    "def smooth_run_not_masked(data,smooth_factor):\n",
    "    smoothed_data = np.zeros_like(data)\n",
    "    for i,d in enumerate(data):\n",
    "        smoothed_data[i] = gaussian_filter(data[i], sigma=smooth_factor, order=0, output=None,\n",
    "                 mode='reflect', cval=0.0, truncate=4.0)\n",
    "    return smoothed_data\n",
    "\n",
    "def delay_one(mat, d):\n",
    "        # delays a matrix by a delay d. Positive d ==> row t has row t-d\n",
    "    new_mat = np.zeros_like(mat)\n",
    "    if d>0:\n",
    "        new_mat[d:] = mat[:-d]\n",
    "    elif d<0:\n",
    "        new_mat[:d] = mat[-d:]\n",
    "    else:\n",
    "        new_mat = mat\n",
    "    return new_mat\n",
    "\n",
    "def delay_mat(mat, delays):\n",
    "        # delays a matrix by a set of delays d.\n",
    "        # a row t in the returned matrix has the concatenated:\n",
    "        # row(t-delays[0],t-delays[1]...t-delays[last] )\n",
    "    new_mat = np.concatenate([delay_one(mat, d) for d in delays],axis = -1)\n",
    "    return new_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b561974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_ind(n, n_folds):\n",
    "    ind = np.zeros((n))\n",
    "    n_items = int(np.floor(n/n_folds))\n",
    "    for i in range(0,n_folds -1):\n",
    "        ind[i*n_items:(i+1)*n_items] = i\n",
    "    ind[(n_folds-1)*n_items:] = (n_folds-1)\n",
    "    return ind\n",
    "\n",
    "def TR_to_word_CV_ind(TR_train_indicator,SKIP_WORDS=20,END_WORDS=5176):\n",
    "    time = np.load('./data/fMRI/time_fmri.npy')\n",
    "    runs = np.load('./data/fMRI/runs_fmri.npy') \n",
    "    time_words = np.load('./data/fMRI/time_words_fmri.npy')\n",
    "    time_words = time_words[SKIP_WORDS:END_WORDS]\n",
    "        \n",
    "    word_train_indicator = np.zeros([len(time_words)], dtype=bool)    \n",
    "    words_id = np.zeros([len(time_words)],dtype=int)\n",
    "    # w=find what TR each word belongs to\n",
    "    for i in range(len(time_words)):                \n",
    "        words_id[i] = np.where(time_words[i]> time)[0][-1]\n",
    "        \n",
    "        if words_id[i] <= len(runs) - 15:\n",
    "            offset = runs[int(words_id[i])]*20 + (runs[int(words_id[i])]-1)*15\n",
    "            if TR_train_indicator[int(words_id[i])-offset-1] == 1:\n",
    "                word_train_indicator[i] = True\n",
    "    return word_train_indicator   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b0a4c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test is the full NLP feature\n",
    "# train/test_pca is the NLP feature reduced to 10 dimensions via PCA that has been fit on the training data\n",
    "# feat_dir is the directory where the NLP features are stored\n",
    "# train_indicator is an array of 0s and 1s indicating whether the word at this index is in the training set\n",
    "def get_nlp_features_fixed_length(layer, seq_len, feat_type, feat_dir, train_indicator, SKIP_WORDS=20, END_WORDS=5176):\n",
    "    \n",
    "    loaded = np.load(feat_dir + feat_type + '_length_'+str(seq_len)+ '_layer_' + str(layer) + '.npy')\n",
    "    if feat_type == 'elmo':\n",
    "        train = loaded[SKIP_WORDS:END_WORDS,:][:,:512][train_indicator]   # only forward LSTM\n",
    "        test = loaded[SKIP_WORDS:END_WORDS,:][:,:512][~train_indicator]   # only forward LSTM\n",
    "    elif feat_type == 'bert' or feat_type == 'transformer_xl' or feat_type == 'use':\n",
    "        train = loaded[SKIP_WORDS:END_WORDS,:][train_indicator]\n",
    "        test = loaded[SKIP_WORDS:END_WORDS,:][~train_indicator]\n",
    "    else:\n",
    "        print('Unrecognized NLP feature type {}. Available options elmo, bert, transformer_xl, use'.format(feat_type))\n",
    "    \n",
    "    pca = PCA(n_components=10, svd_solver='full')\n",
    "    pca.fit(train)\n",
    "    train_pca = pca.transform(train)\n",
    "    test_pca = pca.transform(test)\n",
    "\n",
    "    return train, test, train_pca, test_pca \n",
    "\n",
    "     \n",
    "def prepare_fmri_features(train_features, test_features, word_train_indicator, TR_train_indicator, SKIP_WORDS=20, END_WORDS=5176):\n",
    "        \n",
    "    time = np.load('./data/fMRI/time_fmri.npy')\n",
    "    runs = np.load('./data/fMRI/runs_fmri.npy') \n",
    "    time_words = np.load('./data/fMRI/time_words_fmri.npy')\n",
    "    time_words = time_words[SKIP_WORDS:END_WORDS]\n",
    "        \n",
    "    words_id = np.zeros([len(time_words)])\n",
    "    # w=find what TR each word belongs to\n",
    "    for i in range(len(time_words)):\n",
    "        words_id[i] = np.where(time_words[i]> time)[0][-1]\n",
    "        \n",
    "    all_features = np.zeros([time_words.shape[0], train_features.shape[1]])\n",
    "    all_features[word_train_indicator] = train_features\n",
    "    all_features[~word_train_indicator] = test_features\n",
    "        \n",
    "    p = all_features.shape[1]\n",
    "    tmp = np.zeros([time.shape[0], p])\n",
    "    for i in range(time.shape[0]):\n",
    "        tmp[i] = np.mean(all_features[(words_id<=i)*(words_id>i-1)],0)\n",
    "    tmp = delay_mat(tmp, np.arange(1,5))\n",
    "\n",
    "    # remove the edges of each run\n",
    "    tmp = np.vstack([zscore(tmp[runs==i][20:-15]) for i in range(1,5)])\n",
    "    tmp = np.nan_to_num(tmp)\n",
    "        \n",
    "    return tmp[TR_train_indicator], tmp[~TR_train_indicator]\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec878029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_class_time_CV_fmri_crossval_ridge(data, predict_feat_dict,\n",
    "                                          regress_feat_names_list = [],method = 'kernel_ridge', \n",
    "                                          lambdas = np.array([0.1,1,10,100,1000]),\n",
    "                                          detrend = False, n_folds = 4, skip=5):\n",
    "    \n",
    "    nlp_feat_type = predict_feat_dict['nlp_feat_type']\n",
    "    feat_dir = predict_feat_dict['nlp_feat_dir']\n",
    "    layer = predict_feat_dict['layer']\n",
    "    seq_len = predict_feat_dict['seq_len']\n",
    "        \n",
    "        \n",
    "    n_words = data.shape[0]\n",
    "    n_voxels = data.shape[1]\n",
    "\n",
    "    ind = CV_ind(n_words, n_folds=n_folds)\n",
    "\n",
    "    corrs = np.zeros((n_folds, n_voxels))\n",
    "    acc = np.zeros((n_folds, n_voxels))\n",
    "    acc_std = np.zeros((n_folds, n_voxels))\n",
    "\n",
    "    all_test_data = []\n",
    "    all_preds = []\n",
    "    \n",
    "    \n",
    "    for ind_num in range(n_folds):\n",
    "        print(ind_num)\n",
    "        train_ind = ind!=ind_num\n",
    "        test_ind = ind==ind_num\n",
    "        \n",
    "        word_CV_ind = TR_to_word_CV_ind(train_ind)\n",
    "        \n",
    "        _,_,tmp_train_features,tmp_test_features = get_nlp_features_fixed_length(layer, seq_len, nlp_feat_type, feat_dir, word_CV_ind)\n",
    "        train_features,test_features = prepare_fmri_features(tmp_train_features, tmp_test_features, word_CV_ind, train_ind)\n",
    "        \n",
    "        print('Features generated!')\n",
    "        # split data\n",
    "        train_data = data[train_ind]\n",
    "        test_data = data[test_ind]\n",
    "\n",
    "        # skip TRs between train and test data\n",
    "        if ind_num == 0: # just remove from front end\n",
    "            train_data = train_data[skip:,:]\n",
    "            train_features = train_features[skip:,:]\n",
    "        elif ind_num == n_folds-1: # just remove from back end\n",
    "            train_data = train_data[:-skip,:]\n",
    "            train_features = train_features[:-skip,:]\n",
    "        else:\n",
    "            test_data = test_data[skip:-skip,:]\n",
    "            test_features = test_features[skip:-skip,:]\n",
    "\n",
    "        # normalize data\n",
    "        train_data = np.nan_to_num(zscore(np.nan_to_num(train_data)))\n",
    "        test_data = np.nan_to_num(zscore(np.nan_to_num(test_data)))\n",
    "        all_test_data.append(test_data)\n",
    "        \n",
    "        train_features = np.nan_to_num(zscore(train_features))\n",
    "        test_features = np.nan_to_num(zscore(test_features)) \n",
    "        \n",
    "        start_time = tm.time()\n",
    "        print('Starting training...')\n",
    "        print(train_data.shape, train_features.shape)\n",
    "        weights, chosen_lambdas = cross_val_ridge(train_features, train_data, n_splits = 10, lambdas = np.array([10**i for i in range(-6,10)]), method = 'plain',do_plot = False)\n",
    "#         weights, chosen_lambdas = cross_val_ridge(train_data, train_features, n_splits = 10, lambdas = np.array([10**i for i in range(-6,10)]), method = 'plain',do_plot = False)\n",
    "#         rd = Ridge(alpha = lmbda)\n",
    "#         rd.fit(train_data, train_features)\n",
    "#         preds = rd.predict(test+)\n",
    "#         preds = np.dot(test_data, weights)\n",
    "        preds = np.dot(test_features, weights)\n",
    "        corrs[ind_num,:] = corr(preds, test_data)\n",
    "        all_preds.append(preds)\n",
    "            \n",
    "        print('fold {} completed, took {} seconds'.format(ind_num, tm.time()-start_time))\n",
    "        del weights\n",
    "\n",
    "    return corrs, acc, acc_std, np.vstack(all_preds), np.vstack(all_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "950f0f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classify_neighborhoods(Ypred, Y, n_class=20, nSample = 1000,pair_samples = [],neighborhoods=[]):\n",
    "    # n_class = how many words to classify at once\n",
    "    # nSample = how many words to classify\n",
    "\n",
    "    voxels = Y.shape[-1]\n",
    "    neighborhoods = np.asarray(neighborhoods, dtype=int)\n",
    "\n",
    "    import time as tm\n",
    "\n",
    "    acc = np.full([nSample, Y.shape[-1]], np.nan)\n",
    "    acc2 = np.full([nSample, Y.shape[-1]], np.nan)\n",
    "    test_word_inds = []\n",
    "\n",
    "    if len(pair_samples)>0:\n",
    "        Ypred2 = Ypred[pair_samples>=0]\n",
    "        Y2 = Y[pair_samples>=0]\n",
    "        pair_samples2 = pair_samples[pair_samples>=0]\n",
    "    else:\n",
    "        Ypred2 = Ypred\n",
    "        Y2 = Y\n",
    "        pair_samples2 = pair_samples\n",
    "    n = Y2.shape[0]\n",
    "    start_time = tm.time()\n",
    "    for idx in range(nSample):\n",
    "        \n",
    "        idx_real = np.random.choice(n, n_class)\n",
    "\n",
    "        sample_real = Y2[idx_real]\n",
    "        sample_pred_correct = Ypred2[idx_real]\n",
    "\n",
    "        if len(pair_samples2) == 0:\n",
    "            idx_wrong = np.random.choice(n, n_class)\n",
    "        else:\n",
    "            idx_wrong = sample_same_but_different(idx_real,pair_samples2)\n",
    "        sample_pred_incorrect = Ypred2[idx_wrong]\n",
    "\n",
    "        #print(sample_pred_incorrect.shape)\n",
    "\n",
    "        # compute distances within neighborhood\n",
    "        dist_correct = np.sum((sample_real - sample_pred_correct)**2,0)\n",
    "        dist_incorrect = np.sum((sample_real - sample_pred_incorrect)**2,0)\n",
    "\n",
    "        neighborhood_dist_correct = np.array([np.sum(dist_correct[neighborhoods[v,neighborhoods[v,:]>-1]]) for v in range(voxels)])\n",
    "        neighborhood_dist_incorrect = np.array([np.sum(dist_incorrect[neighborhoods[v,neighborhoods[v,:]>-1]]) for v in range(voxels)])\n",
    "\n",
    "\n",
    "        acc[idx,:] = (neighborhood_dist_correct < neighborhood_dist_incorrect)*1.0 + (neighborhood_dist_correct == neighborhood_dist_incorrect)*0.5\n",
    "\n",
    "        test_word_inds.append(idx_real)\n",
    "    print('Classification for fold done. Took {} seconds'.format(tm.time()-start_time))\n",
    "    return np.nanmean(acc,0), np.nanstd(acc,0), acc, np.array(test_word_inds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26536f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./data/fMRI/data_subject_F.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75aaddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_feat_dict = {}\n",
    "predict_feat_dict['nlp_feat_type'] = 'bert'\n",
    "predict_feat_dict['nlp_feat_dir'] = './data/bert_5/'\n",
    "predict_feat_dict['layer'] = 0\n",
    "predict_feat_dict['seq_len'] = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "880f9a96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/shivansh/cogai/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/scratch/shivansh/cogai/lib/python3.6/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features generated!\n",
      "Starting training...\n",
      "(904, 27905) (904, 40)\n",
      "fold 0 completed, took 13.681169986724854 seconds\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/shivansh/cogai/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/scratch/shivansh/cogai/lib/python3.6/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features generated!\n",
      "Starting training...\n",
      "(909, 27905) (909, 40)\n",
      "fold 1 completed, took 11.799295425415039 seconds\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/shivansh/cogai/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/scratch/shivansh/cogai/lib/python3.6/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features generated!\n",
      "Starting training...\n",
      "(909, 27905) (909, 40)\n",
      "fold 2 completed, took 12.222885608673096 seconds\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/shivansh/cogai/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/scratch/shivansh/cogai/lib/python3.6/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features generated!\n",
      "Starting training...\n",
      "(901, 27905) (901, 40)\n",
      "fold 3 completed, took 11.700167179107666 seconds\n"
     ]
    }
   ],
   "source": [
    "corrs_t, _, _, preds_t, test_t = run_class_time_CV_fmri_crossval_ridge(data,\n",
    "                                                                predict_feat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "26eca7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27905, 80)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighborhoods = np.load('./data/voxel_neighborhoods/F_ars_auto2.npy')\n",
    "neighborhoods.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06d1a933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0252041 ,  0.02277711,  0.06329133, ..., -0.13582168,\n",
       "        -0.08915409, -0.13629759],\n",
       "       [-0.02069957,  0.00907601,  0.04477364, ...,  0.018282  ,\n",
       "        -0.06493876, -0.03058781],\n",
       "       [-0.03403571, -0.0169057 ,  0.04692654, ..., -0.06981226,\n",
       "         0.04372193,  0.04817806],\n",
       "       [ 0.05400679,  0.07125343,  0.06450724, ...,  0.04111747,\n",
       "         0.04404759,  0.10431518]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fbfa743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    2,    4, ..., 2696, 2698, 2700], dtype=uint16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8759021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
